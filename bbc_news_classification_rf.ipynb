{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MiladNlpAi/bbc_news_classification_nlp/blob/main/bbc_news_classification_rf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S53uHknSSbgE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import Counter\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poDg7Sohhvws"
      },
      "outputs": [],
      "source": [
        "# Load and inspect the dataset\n",
        "df = pd.read_csv('/content/bbc-text.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEc6EbIxilNa"
      },
      "outputs": [],
      "source": [
        "# Quick category distribution check\n",
        "sns.countplot(data=df, x='category', palette='viridis')\n",
        "plt.title(\"Distribution of News Categories\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_EVuy1fi8-T"
      },
      "outputs": [],
      "source": [
        "# Download required NLTK resources\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Initialize tools for text preprocessing\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Basic text cleaning + tokenization + stemming + lemmatization\n",
        "def preprocess_text(text):\n",
        "  text = text.lower()\n",
        "  punctuation = r\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~،؛؟«»\"\"\"\n",
        "  text = re.sub(f\"[{re.escape(punctuation)}]\", '', text)\n",
        "  tokens = nltk.word_tokenize(text)\n",
        "  tokens_with_out_stop = [word for word in tokens if word not in stop_words]\n",
        "  stemmed_tokens = [stemmer.stem(word) for word in tokens_with_out_stop]\n",
        "  lemmatized_tokens = [lemmatizer.lemmatize(token) for token in stemmed_tokens]\n",
        "  return lemmatized_tokens\n",
        "\n",
        "# Apply preprocessing to text column\n",
        "df['preprocessed_text'] = df['text'].apply(preprocess_text)\n",
        "df['preprocessed_text'] = df['preprocessed_text'].apply(lambda x: \" \".join(x))\n",
        "df[['text', 'preprocessed_text']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13OlcsCdxWdT"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "# Generate word clouds for each category\n",
        "for category in df['category'].unique():\n",
        "    category_text = \" \".join(df[df['category'] == category]['preprocessed_text'])\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(category_text)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.title(f\"Word Cloud for {category}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(category_text)\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.title(f\"Word Cloud for {category}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdejCKTp3aia"
      },
      "outputs": [],
      "source": [
        "# Analyze most common tokens after preprocessing\n",
        "all_words = [word for text in df['preprocessed_text'] for word in text.split()]\n",
        "word_freq = Counter(all_words)\n",
        "most_common_words = word_freq.most_common(20)\n",
        "common_df = pd.DataFrame(most_common_words, columns=['Word', 'Frequency'])\n",
        "\n",
        "sns.barplot(data=common_df, x='Frequency', y='Word', palette='plasma')\n",
        "plt.title(\"Most Common Words After Preprocessing\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pcx33c1F4NCA"
      },
      "outputs": [],
      "source": [
        "# TF-IDF vectorization\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(df['preprocessed_text'])\n",
        "\n",
        "# TF-IDF matrix shape\n",
        "tfidf_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check top features in first doc\n",
        "tfidf_sample = pd.DataFrame(tfidf_matrix[0].toarray().T, columns=[\"TF-IDF Score\"])\n",
        "tfidf_sample['Word'] = tfidf_vectorizer.get_feature_names_out()\n",
        "tfidf_sample = tfidf_sample.sort_values(by=\"TF-IDF Score\", ascending=False).head(10)\n",
        "\n",
        "sns.barplot(data=tfidf_sample, x='TF-IDF Score', y='Word', palette='cividis')\n",
        "plt.title(\"Top 10 TF-IDF Features for First Document\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SEUzq7vXO_Ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode text labels to numeric\n",
        "label_encoder = LabelEncoder()\n",
        "df['category_encoded'] = label_encoder.fit_transform(df['category'])\n",
        "\n",
        "# Just to check encoding\n",
        "df[['category', 'category_encoded']].drop_duplicates().sort_values('category_encoded')"
      ],
      "metadata": {
        "id": "LXx90wWxPY1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Features and labels\n",
        "X = tfidf_matrix\n",
        "y = df['category_encoded']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "id": "467qdDBMPudc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Classifier\n",
        "classifier = RandomForestClassifier(min_samples_split=5, n_estimators=200, random_state=42)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "GBHvHIQcPy6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test data\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Classification report to evaluate model performance\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "# Confusion matrix to visualize model performance\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot confusion matrix\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"YlGnBu\", xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Overall Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "XFX8E0_KP0uM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final preview of the data\n",
        "df.head()"
      ],
      "metadata": {
        "id": "A9HKB9dsP2Kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save predictions for analysis or inspection\n",
        "test_indices = y_test.index\n",
        "output_df = pd.DataFrame({\n",
        "    'index': test_indices,\n",
        "    'preprocessed_text': df.loc[test_indices, 'preprocessed_text'],\n",
        "    'predicted_category': label_encoder.inverse_transform(y_pred)\n",
        "})\n",
        "output_df.to_csv('predictions.csv', index=False)\n",
        "output_df.head()"
      ],
      "metadata": {
        "id": "t0H_8DP7P4-I"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6uA/wgQ/jf6Fcfz9L6WjB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}